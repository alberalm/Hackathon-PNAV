{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def obtain_webpage(species_type):\n",
    "    base_webpage = \"https://www.miteco.gob.es/es/biodiversidad/temas/inventarios-nacionales/inventario-especies-terrestres/inventario-nacional-de-biodiversidad/bdn-ieet-atlas-vert-\"\n",
    "    if species_type == \"mamiferos\":\n",
    "        return f\"{base_webpage}mamif.html\"\n",
    "    elif species_type == \"aves\":\n",
    "        return f\"{base_webpage}aves.html\"\n",
    "    elif species_type == \"reptiles\":\n",
    "        return f\"{base_webpage}reptiles.html\"\n",
    "    elif species_type == \"anfibios\":\n",
    "        return f\"{base_webpage}anfibios.html\"\n",
    "    elif species_type == \"peces\":\n",
    "        return f\"{base_webpage}peces.html\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Function to download a file\n",
    "def download_file(url, folder):\n",
    "    filename = os.path.join(folder, os.path.basename(url))  # Extract filename\n",
    "    response = requests.get(url, stream=True)  # Download file\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "    else:\n",
    "        print(f\"Failed to download: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download Delichon urbica from group aves\n",
      "Failed to download Gelochelidon nilotica from group aves\n",
      "Failed to download Hirundo daurica from group aves\n",
      "Failed to download Lagopus mutus from group aves\n",
      "Failed to download Lanius meridionalis from group aves\n",
      "Failed to download Miliaria calandra from group aves\n",
      "Failed to download Tachymarptis melba from group aves\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "for group in [\"mamiferos\", \"aves\", \"reptiles\", \"anfibios\", \"peces\"]:\n",
    "\n",
    "    os.makedirs(f\"Datos IEET - {group}\", exist_ok=True)\n",
    "    driver.get(obtain_webpage(group))\n",
    "\n",
    "    table = driver.find_element(By.ID, \"xsltExecuted\")\n",
    "    # Find all rows in the table\n",
    "    table_rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Iterate through each row\n",
    "    rows = {}\n",
    "    for row in table_rows:\n",
    "        # Get all columns (cells) in the row\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        \n",
    "        # Extract the text and hyperlinks (if present)\n",
    "        for col in columns:\n",
    "            # Check if the column contains a link\n",
    "            link = col.find_element(By.TAG_NAME, \"a\") if col.find_elements(By.TAG_NAME, \"a\") else None\n",
    "            if link:\n",
    "                rows[link.text.strip()] = link.get_attribute(\"href\")\n",
    "\n",
    "    for key, value in rows.items():\n",
    "        \n",
    "        driver.get(value)\n",
    "        species_links = {}\n",
    "\n",
    "        # Find the table by ID\n",
    "        table = driver.find_element(By.ID, \"xsltExecuted\")\n",
    "\n",
    "        # Get all table rows except the header\n",
    "        table_rows = table.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "\n",
    "        for row in table_rows:\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            \n",
    "            if len(cells) >= 4:  # Ensure it's a valid row with data\n",
    "                scientific_name = cells[0].text.strip()\n",
    "                zip_link = cells[2].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\") if cells[2].find_elements(By.TAG_NAME, \"a\") else None\n",
    "                pdf_link = cells[3].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\") if cells[3].find_elements(By.TAG_NAME, \"a\") else None\n",
    "\n",
    "                species_links[scientific_name] = (zip_link, pdf_link)\n",
    "\n",
    "        # Print results\n",
    "        for species, links in species_links.items():\n",
    "            # Directory to save downloads\n",
    "            download_dir = f\"Datos IEET - {group}/{species}\"\n",
    "            os.makedirs(download_dir, exist_ok=True)\n",
    "            try:\n",
    "                download_file(links[0], download_dir)\n",
    "            except:\n",
    "                print(f\"Failed to download {species} from group {group}\")\n",
    "            try:\n",
    "                download_file(links[1], download_dir)\n",
    "            except:\n",
    "                print(f\"Failed to download {species} from group {group}\")\n",
    "            # Extract zip files\n",
    "            for file in os.listdir(download_dir):\n",
    "                if os.path.splitext(file)[1] == \".zip\":\n",
    "                    with zipfile.ZipFile(f\"{download_dir}/{file}\", \"r\") as zip_ref:\n",
    "                        zip_ref.extractall(download_dir)\n",
    "                    os.remove(f\"{download_dir}/{file}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
